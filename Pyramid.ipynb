{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [
     10
    ],
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#imports\n",
    "import cv2\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import glob\n",
    "import os\n",
    "import time\n",
    "import math\n",
    "from collections import defaultdict\n",
    "from numpy.linalg import inv\n",
    "\n",
    "if 'oldsysstdout' not in locals():\n",
    "    import sys\n",
    "    oldsysstdout = sys.stdout\n",
    "    class flushfile():\n",
    "        def __init__(self, f):\n",
    "            self.f = f\n",
    "        def __getattr__(self,name): \n",
    "            return object.__getattribute__(self.f, name)\n",
    "        def write(self, x):\n",
    "            self.f.write(x)\n",
    "            self.f.flush()\n",
    "        def flush(self):\n",
    "            self.f.flush()\n",
    "    sys.stdout = flushfile(sys.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "\n",
    "def nothing(x):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     1,
     17,
     20,
     26,
     30,
     38,
     48,
     70,
     74,
     96,
     99,
     102,
     105,
     108,
     112,
     115,
     118,
     124,
     126,
     173
    ],
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "visualize = True\n",
    "def detect(img):\n",
    "    img_gs = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    img_gs = clahe.apply(img_gs)\n",
    "    img_gs_f = np.float32(img_gs)\n",
    "    dst = cv2.cornerHarris(img_gs_f,2,3,0.04)\n",
    "    #result is dilated for marking the corners, not important\n",
    "    dst = cv2.dilate(dst,None)\n",
    "    \n",
    "    coords = np.transpose(np.nonzero(dst>0.01*dst.max()))\n",
    "    # Threshold for an optimal value, it may vary depending on the image.\n",
    "    #if visualize:\n",
    "        #img[dst>0.01*dst.max()]=[0,0,255]\n",
    "    #print coords\n",
    "    return (coords,img_gs_f, img_gs)\n",
    "\n",
    "def dist2(a, b):\n",
    "    return (a[0]-b[0])*(a[0]-b[0]) + (a[1]-b[1])*(a[1]-b[1])\n",
    "\n",
    "def subimage(image, center, ts, tc, width, height):\n",
    "    v_x = (tc, ts)\n",
    "    v_y = (-ts,tc)\n",
    "    s_x = center[0] - v_x[0] * (width / 2) - v_y[0] * (height / 2)\n",
    "    s_y = center[1] - v_x[1] * (width / 2) - v_y[1] * (height / 2)\n",
    "\n",
    "    mapping = np.array([[v_x[0],v_y[0], s_x],\n",
    "                        [v_x[1],v_y[1], s_y]])\n",
    "\n",
    "\n",
    "    return cv2.warpAffine(\n",
    "        image,\n",
    "        mapping,\n",
    "        (int(width), int(height)),\n",
    "        flags=cv2.WARP_INVERSE_MAP,\n",
    "        borderMode=cv2.BORDER_REPLICATE)\n",
    "\n",
    "#get image of a line between two points with given width\n",
    "def subimage2(image, c1, c2, width):\n",
    "    w = c1[0]-c2[0]\n",
    "    h = c1[1]-c2[1]\n",
    "    center = topoint((c1+c2)/2)\n",
    "    c = math.sqrt(dist2(c1, c2))\n",
    "    ts = -w/c\n",
    "    tc = h/c\n",
    "    #print (topoint(c1), topoint(c2), center, ts, tc, w, h, c)\n",
    "    return subimage(image, center, ts, tc, width, c)\n",
    "\n",
    "def circleCoords(coords, mask_zero, radius = 2, maxSize = 22):\n",
    "    mask = mask_zero[:,:,0].copy()\n",
    "    for c in coords:\n",
    "        cv2.circle(mask, (c[1],c[0]), radius,255,-1)\n",
    "    ret, markers, stats, centroids = cv2.connectedComponentsWithStats(mask)\n",
    "    if visualize:#for visualization only\n",
    "        max_ = np.amax(markers)\n",
    "        markers *= 255/max_\n",
    "        markers = markers.astype(np.uint8)\n",
    "        markers_col = cv2.applyColorMap(markers, cv2.COLORMAP_JET)\n",
    "    candidates = []\n",
    "    for (i,c) in enumerate(centroids):\n",
    "        if  (stats[i,cv2.CC_STAT_WIDTH] < maxSize and stats[i,cv2.CC_STAT_HEIGHT] < maxSize and\n",
    "            (stats[i,cv2.CC_STAT_WIDTH] > 4*radius or stats[i,cv2.CC_STAT_HEIGHT] >4*radius)):\n",
    "            if visualize:\n",
    "                cv2.circle(markers_col, (int(c[0]),int(c[1])), maxSize/2,(0,0,255),1)\n",
    "            candidates += [c]\n",
    "    if visualize:#for visualization only\n",
    "        cv2.imshow('markers_col', markers_col)\n",
    "    return candidates\n",
    "    \n",
    "\n",
    "def topoint(x):\n",
    "    return (int(x[0]),int(x[1]))\n",
    "    \n",
    "\n",
    "def findGraph(candidates, img_gs, max_mean=40):\n",
    "    mask = np.zeros_like(img_gs)\n",
    "    graph = defaultdict(lambda:[])\n",
    "    if visualize:\n",
    "        cv2.imshow('clahe', img_gs)\n",
    "    \n",
    "    for (i,c) in enumerate(candidates):\n",
    "        for j in range(i):\n",
    "            sub = subimage2(img_gs, c, candidates[j],10)\n",
    "            min_ = np.amin(sub, axis = 1)\n",
    "            \n",
    "            \n",
    "            if min_.mean() < max_mean:\n",
    "                if visualize:\n",
    "                    cv2.line(mask, topoint(c), topoint(candidates[j]),255,1)\n",
    "                graph[i] += [j]\n",
    "                graph[j] += [i]\n",
    "    if visualize:\n",
    "        cv2.imshow('graph', mask)\n",
    "    return graph, mask\n",
    "\n",
    "#http://stackoverflow.com/a/246063\n",
    "def CrossProductZ(a,b):\n",
    "    return a[0] * b[1] - a[1] * b[0]\n",
    "\n",
    "def Orientation(a, b, c):\n",
    "    return CrossProductZ(a, b) + CrossProductZ(b, c) + CrossProductZ(c, a)\n",
    "\n",
    "def OrientationC(g, a, b, c):\n",
    "    return Orientation(g[a],g[b],g[c])\n",
    "\n",
    "def add1(a):\n",
    "    return np.append(a,[1])\n",
    "\n",
    "def findHouse(graph, mask_, img, candidates, primary=5, secondary=4, name='_X', color=(0,0,255),img_gs=None):\n",
    "    if visualize:\n",
    "        mask = mask_.copy()\n",
    "    for i in graph: #subgraph localization\n",
    "        if len(graph[i]) != 2:\n",
    "            continue\n",
    "        [a,b] = graph[i]\n",
    "        if len(graph[a]) != primary or len(graph[a]) != primary:\n",
    "            continue\n",
    "        ok = 1\n",
    "        for c in graph[a]:\n",
    "            if c != b and c!= i and len(graph[c]) != secondary:\n",
    "                ok = 0\n",
    "                break\n",
    "        if ok == 0:\n",
    "            continue\n",
    "        if OrientationC(candidates,i,a,b)<0:\n",
    "            (a,b) = (b,a)\n",
    "        for x in [a]+graph[a]:\n",
    "            for y in graph[x]:\n",
    "                if x<y:\n",
    "                    if visualize:\n",
    "                        cv2.line(mask, topoint(candidates[x]), topoint(candidates[y]),255,3)\n",
    "                    cv2.line(img, topoint(candidates[x]), topoint(candidates[y]),color,1)\n",
    "        used = {i: 1, a:1, b:1}\n",
    "        \n",
    "        x = 0\n",
    "        s = 0\n",
    "        if name == '_X':#find middle point\n",
    "            for j in filter(lambda x: x not in used, graph[a]):\n",
    "                s_ = 0\n",
    "                for k in graph[j]:\n",
    "                    s_ += dist2(candidates[j],candidates[k])\n",
    "                if x == 0 or s_ < s:\n",
    "                    x = j\n",
    "                    s = s_\n",
    "            used[x] = 1\n",
    "        cd = filter(lambda x: x not in used, graph[a])\n",
    "        if len(cd) != 2:\n",
    "            #print \"cd has len %d\" %len(cd)\n",
    "            return (None, None)\n",
    "        [c,d] = cd\n",
    "        if OrientationC(candidates,x,c,d)<0:\n",
    "            (c,d) = (d,c)\n",
    "    \n",
    "        points_imdg = [candidates[__] for __ in [a,b,c,d]]#,x,i\n",
    "        if name == '_X':\n",
    "            points_img = [candidates[__] for __ in [a,b,c,d,x]]#,x,i\n",
    "            new_3d = np.float32([[100,0,0],[0,0,0],[100,100,0],[0,100,0],[50,50,0]])\n",
    "        else:\n",
    "            points_img = [candidates[__] for __ in [a,b,c,d]]#,x,i\n",
    "            new_3d = np.float32([[100,0,0],[0,0,0],[100,100,0],[0,100,0]])\n",
    "        p_img = np.array(points_img, np.float32)\n",
    "        cv2.cornerSubPix(img_gs,p_img,(11,11),(-1,-1),criteria)\n",
    "        #cv2.circle(img, topoint(p_img[5]), 5, (255,0,0),-1)\n",
    "        cv2.circle(img, topoint(p_img[0]), 5, (0,0,255),-1)#tr\n",
    "        cv2.circle(img, topoint(p_img[1]), 5, (0,255,0),-1)#tl\n",
    "        #cv2.circle(img, topoint(p_img[4]), 5, (255,255,255),-1)\n",
    "        cv2.circle(img, topoint(p_img[2]), 5, (0,255,255),-1)#br\n",
    "        cv2.circle(img, topoint(p_img[3]), 5, (255,0,255),-1)#bl\n",
    "        return draw3d(img,p_img,new_3d)\n",
    "    #   \n",
    "    return (None,None)\n",
    "\n",
    "goal_3d = np.float32([[50,50,-1]])\n",
    "def draw3d(img, pts, new_3d):\n",
    "    fx = 0.5 + cv2.getTrackbarPos('focal', 'dst') / 50.0\n",
    "    h, w = img.shape[:2]\n",
    "    K = np.float64([[fx*w, 0, 0.5*(w-1)],\n",
    "                    [0, fx*w, 0.5*(h-1)],\n",
    "                    [0.0,0.0,      1.0]])\n",
    "    dist_coef = np.zeros(4)\n",
    "    ret, rvec, tvec = cv2.solvePnP(new_3d, pts, K, dist_coef)\n",
    "    goal_3d[0,2] = -1 * cv2.getTrackbarPos('height', 'dst')\n",
    "    verts = cv2.projectPoints(goal_3d, rvec, tvec, K, dist_coef)[0].reshape(-1, 2)\n",
    "    cv2.circle(img, topoint(verts[0]), 5, (255,255,255),-1)\n",
    "    for p in pts:\n",
    "        cv2.line(img, topoint(p), topoint(verts[0]), (255,255,255),2, -1)\n",
    "\n",
    "def detectHouse(frame, house_type='_X'):\n",
    "    (coords_,img_gs_f, img_gs) = detect(frame)\n",
    "    candidates = circleCoords(coords_, np.zeros_like(frame))\n",
    "    graph, mask = findGraph(candidates, img_gs,max_mean=cv2.getTrackbarPos('max_mean', 'dst'))\n",
    "    findHouse(graph, mask, frame, candidates, 5, 4, '_X', img_gs=img_gs)\n",
    "    #findHouse(graph, mask, frame, candidates, 3, 2, '_N', img_gs=img_gs)\n",
    "    cv2.imshow('dst',frame)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#camera example\n",
    "cv2.namedWindow('dst')\n",
    "cv2.createTrackbar('focal', 'dst', 25, 50, nothing)\n",
    "cv2.createTrackbar('height', 'dst', 50, 200, nothing)\n",
    "cv2.createTrackbar('max_mean', 'dst', 40, 200, nothing)\n",
    "\n",
    "if 'cap' in locals():\n",
    "    cap.release()\n",
    "cap = cv2.VideoCapture(1)#select correct camera\\\n",
    "\n",
    "while(True):\n",
    "    ret, frame = cap.read()\n",
    "    detectHouse(frame)\n",
    "    key = cv2.waitKey(1)\n",
    "    if key & 0xFF == ord('q'):\n",
    "        break\n",
    "if 'cap' in locals():\n",
    "    cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#scanned pictures example\n",
    "mypath = 'frames'\n",
    "cv2.namedWindow('dst')\n",
    "cv2.createTrackbar('focal', 'dst', 25, 50, nothing)\n",
    "cv2.createTrackbar('height', 'dst', 50, 200, nothing)\n",
    "cv2.createTrackbar('max_mean', 'dst', 40, 200, nothing)\n",
    "\n",
    "for f in glob.glob(os.path.join(mypath,'*.jpg')):\n",
    "    frame_orig = cv2.imread(f)\n",
    "    while True:\n",
    "        frame = frame_orig.copy()\n",
    "        detectHouse(frame)\n",
    "        key = cv2.waitKey(100)\n",
    "        if key & 0xFF == ord('q') or key & 0xFF == ord(' '):\n",
    "            break\n",
    "    if key & 0xFF == ord('q'):\n",
    "        break\n",
    "#for f in listdir(mypath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.1.0'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#store frames\n",
    "\n",
    "if 'cap' in locals():\n",
    "    cap.release()\n",
    "cap = cv2.VideoCapture(0)\n",
    "i = 0\n",
    "while(True):\n",
    "    ret, frame = cap.read()\n",
    "    #coords_ = detect(frame)\n",
    "    #clusters = mergeCoords(coords_)\n",
    "    cv2.imwrite('frame_%d.jpg'%i,frame)\n",
    "    cv2.imshow('dst',frame)\n",
    "    i+=1\n",
    "    if cv2.waitKey(500) & 0xFF == ord('q'):\n",
    "        break\n",
    "    #break\n",
    "cap.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
